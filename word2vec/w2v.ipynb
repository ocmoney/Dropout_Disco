{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data import\n",
        "\n",
        "First setting up the db engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "hA2jPyvdYAuW"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Your provided connection string\n",
        "db_uri = 'postgresql+psycopg2://sy91dhb:g5t49ao@178.156.142.230:5432/hd64m1ki'\n",
        "\n",
        "# Create engine\n",
        "engine = create_engine(db_uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "gathering items from the ITEMS table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "B1fvkd1pY4lj",
        "outputId": "b180e852-944f-49f9-ae47-cb55d39770d9"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m      2\u001b[39m \u001b[33;43m  SELECT\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[33;43m    *\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[33;43m  FROM \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhacker_news\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mitems\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m a\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[33;43m  WHERE a.type = \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstory\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m AND a.dead IS NOT TRUE\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m res.head(\u001b[32m10\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\sql.py:734\u001b[39m, in \u001b[36mread_sql\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[39m\n\u001b[32m    724\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql.read_table(\n\u001b[32m    725\u001b[39m         sql,\n\u001b[32m    726\u001b[39m         index_col=index_col,\n\u001b[32m   (...)\u001b[39m\u001b[32m    731\u001b[39m         dtype_backend=dtype_backend,\n\u001b[32m    732\u001b[39m     )\n\u001b[32m    733\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\sql.py:1836\u001b[39m, in \u001b[36mSQLDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   1780\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1781\u001b[39m     sql: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1788\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1789\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m   1790\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1791\u001b[39m \u001b[33;03m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[32m   1792\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1834\u001b[39m \n\u001b[32m   1835\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1836\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1837\u001b[39m     columns = result.keys()\n\u001b[32m   1839\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\sql.py:1659\u001b[39m, in \u001b[36mSQLDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   1657\u001b[39m args = [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[32m   1658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1659\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1660\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.con.execute(sql, *args)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\base.py:1776\u001b[39m, in \u001b[36mConnection.exec_driver_sql\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1771\u001b[39m execution_options = \u001b[38;5;28mself\u001b[39m._execution_options.merge_with(\n\u001b[32m   1772\u001b[39m     execution_options\n\u001b[32m   1773\u001b[39m )\n\u001b[32m   1775\u001b[39m dialect = \u001b[38;5;28mself\u001b[39m.dialect\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1777\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1778\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1779\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1780\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1782\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\base.py:1843\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exec_insertmany_context(dialect, context)\n\u001b[32m   1842\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[32m   1845\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\base.py:1983\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1980\u001b[39m     result = context._setup_result_proxy()\n\u001b[32m   1982\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1983\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1984\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\base.py:2355\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2353\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2354\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2355\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc_info[\u001b[32m1\u001b[39m].with_traceback(exc_info[\u001b[32m2\u001b[39m])\n\u001b[32m   2356\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2357\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reentrant_error\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\base.py:1964\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1962\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1963\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1966\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n\u001b[32m   1969\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_cursor_execute(\n\u001b[32m   1970\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1971\u001b[39m         cursor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1975\u001b[39m         context.executemany,\n\u001b[32m   1976\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\default.py:945\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\utf_8.py:15\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(input, errors)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[32m     13\u001b[39m encode = codecs.utf_8_encode\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors=\u001b[33m'\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs.utf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIncrementalEncoder\u001b[39;00m(codecs.IncrementalEncoder):\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "res = pd.read_sql(\"\"\"\n",
        "  SELECT\n",
        "    *\n",
        "  FROM \"hacker_news\".\"items\" a\n",
        "  WHERE a.type = 'story' AND a.dead IS NOT TRUE AND time > DATE '2024-01-01'\n",
        "\"\"\", engine)\n",
        "\n",
        "res.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "IcSFS8bcZYYY",
        "outputId": "f898875d-1061-45b8-d51b-27de8483f560"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"users\",\n  \"rows\": 40,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"__--__\",\n          \"_-___________-_\",\n          \"__\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2007-02-20 17:52:01\",\n        \"max\": \"2022-12-21 15:25:09\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"2012-11-28 19:41:52\",\n          \"2019-01-17 15:17:37\",\n          \"2007-02-20 17:52:01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"karma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 438,\n        \"min\": -20,\n        \"max\": 2315,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          1,\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"about\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\",\n          \"just wandering around\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"submitted\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "users"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ed4f3c4a-8e0f-4d5e-8b89-36a129044329\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>created</th>\n",
              "      <th>karma</th>\n",
              "      <th>about</th>\n",
              "      <th>submitted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>_------------_</td>\n",
              "      <td>2018-10-30 22:25:25</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>[18723436, 18710285, 18341881]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>_-----_</td>\n",
              "      <td>2022-12-07 19:45:14</td>\n",
              "      <td>38</td>\n",
              "      <td>None</td>\n",
              "      <td>[34353215, 34346450, 34314090, 34277524, 34262...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>_--</td>\n",
              "      <td>2016-08-27 21:06:13</td>\n",
              "      <td>-1</td>\n",
              "      <td>None</td>\n",
              "      <td>[12390950, 12390899, 12373932]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>_---____--_--</td>\n",
              "      <td>2022-03-17 12:35:53</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>[30710444]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>_--_</td>\n",
              "      <td>2014-08-02 11:52:04</td>\n",
              "      <td>-7</td>\n",
              "      <td>None</td>\n",
              "      <td>[10919437, 8668545, 8349770, 8335037]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>_--_----_--_</td>\n",
              "      <td>2011-08-09 00:17:37</td>\n",
              "      <td>5</td>\n",
              "      <td>just wandering around</td>\n",
              "      <td>[3057854, 2936170, 2881969, 2861960]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>_--__--__</td>\n",
              "      <td>2020-02-24 17:36:53</td>\n",
              "      <td>21</td>\n",
              "      <td>None</td>\n",
              "      <td>[41506632, 41207475, 33171311, 31927691, 31927...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>_--___-___</td>\n",
              "      <td>2019-07-09 20:49:22</td>\n",
              "      <td>11</td>\n",
              "      <td>None</td>\n",
              "      <td>[24152556, 23797608, 22321065, 22239248, 21973...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>_-_-_-</td>\n",
              "      <td>2013-10-18 00:43:28</td>\n",
              "      <td>-20</td>\n",
              "      <td></td>\n",
              "      <td>[6569743, 6569721, 6569642, 6569580, 6569556, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>_-_-_-_</td>\n",
              "      <td>2015-02-10 08:08:56</td>\n",
              "      <td>12</td>\n",
              "      <td></td>\n",
              "      <td>[9204764, 9204535, 9105003, 9088165]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>_-_-_-_-</td>\n",
              "      <td>2015-08-23 15:28:29</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>[10105578]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>_-__---</td>\n",
              "      <td>2014-06-30 14:22:20</td>\n",
              "      <td>174</td>\n",
              "      <td>None</td>\n",
              "      <td>[18057994, 17031701, 15279081, 14841480, 14310...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>_-_-__-_-_-</td>\n",
              "      <td>2022-10-05 12:18:49</td>\n",
              "      <td>15</td>\n",
              "      <td>None</td>\n",
              "      <td>[41469525, 41410205, 41060688, 41050614, 40923...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>_-__--____--</td>\n",
              "      <td>2017-04-20 21:52:46</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>[14161117, 14161031, 14160939, 14160880, 14160...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>_-____-_</td>\n",
              "      <td>2022-12-21 15:25:09</td>\n",
              "      <td>105</td>\n",
              "      <td>None</td>\n",
              "      <td>[36587023, 36455130, 36423629, 36423607, 36422...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>__</td>\n",
              "      <td>2007-02-20 17:52:01</td>\n",
              "      <td>1113</td>\n",
              "      <td></td>\n",
              "      <td>[1080426, 1080215, 1079587, 1056151, 1049571, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>_-___________-_</td>\n",
              "      <td>2019-01-17 15:17:37</td>\n",
              "      <td>2315</td>\n",
              "      <td>None</td>\n",
              "      <td>[26364629, 26354658, 26354625, 26354602, 26354...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>__-</td>\n",
              "      <td>2020-11-21 00:51:49</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>[25167100]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>___</td>\n",
              "      <td>2010-01-13 18:47:36</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>[1051883]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>__--__</td>\n",
              "      <td>2012-11-28 19:41:52</td>\n",
              "      <td>247</td>\n",
              "      <td>None</td>\n",
              "      <td>[7356782, 7356780, 7339938, 7309297, 7309148, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>___----___</td>\n",
              "      <td>2019-12-13 21:45:31</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>[21785854]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>____---___-</td>\n",
              "      <td>2022-09-12 09:22:40</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>[32807441]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>_____-___</td>\n",
              "      <td>2020-01-13 23:53:47</td>\n",
              "      <td>23</td>\n",
              "      <td>None</td>\n",
              "      <td>[39488945, 39462127, 39449730, 39240682, 38959...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>______</td>\n",
              "      <td>2011-02-14 23:37:47</td>\n",
              "      <td>438</td>\n",
              "      <td>None</td>\n",
              "      <td>[41015712, 39304327, 39091136, 38517472, 38264...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>______---______</td>\n",
              "      <td>2020-03-11 21:15:39</td>\n",
              "      <td>-3</td>\n",
              "      <td>None</td>\n",
              "      <td>[22550871]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>______-</td>\n",
              "      <td>2021-05-03 18:00:01</td>\n",
              "      <td>611</td>\n",
              "      <td>None</td>\n",
              "      <td>[27569937, 27569883, 27569875, 27539973, 27528...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>______-_-______</td>\n",
              "      <td>2022-01-28 01:36:23</td>\n",
              "      <td>1094</td>\n",
              "      <td>None</td>\n",
              "      <td>[31339806, 31339070, 31332092, 31328996, 31322...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>_______</td>\n",
              "      <td>2010-08-30 11:19:09</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>[1645809]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>_______-_______</td>\n",
              "      <td>2014-09-10 20:07:06</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>[11654135, 8298420]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>__________</td>\n",
              "      <td>2012-08-28 23:33:57</td>\n",
              "      <td>8</td>\n",
              "      <td>None</td>\n",
              "      <td>[4448313, 4448275, 4447066, 4446456, 4446231]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed4f3c4a-8e0f-4d5e-8b89-36a129044329')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed4f3c4a-8e0f-4d5e-8b89-36a129044329 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed4f3c4a-8e0f-4d5e-8b89-36a129044329');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ac29b1e6-1596-4691-8b8e-34939ed7e133\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ac29b1e6-1596-4691-8b8e-34939ed7e133')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ac29b1e6-1596-4691-8b8e-34939ed7e133 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                 id             created  karma                  about  \\\n",
              "0    _------------_ 2018-10-30 22:25:25      5                   None   \n",
              "1           _-----_ 2022-12-07 19:45:14     38                   None   \n",
              "2               _-- 2016-08-27 21:06:13     -1                   None   \n",
              "3     _---____--_-- 2022-03-17 12:35:53      6                   None   \n",
              "4              _--_ 2014-08-02 11:52:04     -7                   None   \n",
              "5      _--_----_--_ 2011-08-09 00:17:37      5  just wandering around   \n",
              "6         _--__--__ 2020-02-24 17:36:53     21                   None   \n",
              "7        _--___-___ 2019-07-09 20:49:22     11                   None   \n",
              "8            _-_-_- 2013-10-18 00:43:28    -20                          \n",
              "9           _-_-_-_ 2015-02-10 08:08:56     12                          \n",
              "10         _-_-_-_- 2015-08-23 15:28:29      2                   None   \n",
              "11          _-__--- 2014-06-30 14:22:20    174                   None   \n",
              "12      _-_-__-_-_- 2022-10-05 12:18:49     15                   None   \n",
              "13     _-__--____-- 2017-04-20 21:52:46      2                   None   \n",
              "14         _-____-_ 2022-12-21 15:25:09    105                   None   \n",
              "15               __ 2007-02-20 17:52:01   1113                          \n",
              "16  _-___________-_ 2019-01-17 15:17:37   2315                   None   \n",
              "17              __- 2020-11-21 00:51:49      1                   None   \n",
              "18              ___ 2010-01-13 18:47:36      1                   None   \n",
              "19           __--__ 2012-11-28 19:41:52    247                   None   \n",
              "20       ___----___ 2019-12-13 21:45:31      2                   None   \n",
              "21      ____---___- 2022-09-12 09:22:40      1                   None   \n",
              "22        _____-___ 2020-01-13 23:53:47     23                   None   \n",
              "23           ______ 2011-02-14 23:37:47    438                   None   \n",
              "24  ______---______ 2020-03-11 21:15:39     -3                   None   \n",
              "25          ______- 2021-05-03 18:00:01    611                   None   \n",
              "26  ______-_-______ 2022-01-28 01:36:23   1094                   None   \n",
              "27          _______ 2010-08-30 11:19:09      1                   None   \n",
              "28  _______-_______ 2014-09-10 20:07:06      2                   None   \n",
              "29       __________ 2012-08-28 23:33:57      8                   None   \n",
              "\n",
              "                                            submitted  \n",
              "0                      [18723436, 18710285, 18341881]  \n",
              "1   [34353215, 34346450, 34314090, 34277524, 34262...  \n",
              "2                      [12390950, 12390899, 12373932]  \n",
              "3                                          [30710444]  \n",
              "4               [10919437, 8668545, 8349770, 8335037]  \n",
              "5                [3057854, 2936170, 2881969, 2861960]  \n",
              "6   [41506632, 41207475, 33171311, 31927691, 31927...  \n",
              "7   [24152556, 23797608, 22321065, 22239248, 21973...  \n",
              "8   [6569743, 6569721, 6569642, 6569580, 6569556, ...  \n",
              "9                [9204764, 9204535, 9105003, 9088165]  \n",
              "10                                         [10105578]  \n",
              "11  [18057994, 17031701, 15279081, 14841480, 14310...  \n",
              "12  [41469525, 41410205, 41060688, 41050614, 40923...  \n",
              "13  [14161117, 14161031, 14160939, 14160880, 14160...  \n",
              "14  [36587023, 36455130, 36423629, 36423607, 36422...  \n",
              "15  [1080426, 1080215, 1079587, 1056151, 1049571, ...  \n",
              "16  [26364629, 26354658, 26354625, 26354602, 26354...  \n",
              "17                                         [25167100]  \n",
              "18                                          [1051883]  \n",
              "19  [7356782, 7356780, 7339938, 7309297, 7309148, ...  \n",
              "20                                         [21785854]  \n",
              "21                                         [32807441]  \n",
              "22  [39488945, 39462127, 39449730, 39240682, 38959...  \n",
              "23  [41015712, 39304327, 39091136, 38517472, 38264...  \n",
              "24                                         [22550871]  \n",
              "25  [27569937, 27569883, 27569875, 27539973, 27528...  \n",
              "26  [31339806, 31339070, 31332092, 31328996, 31322...  \n",
              "27                                          [1645809]  \n",
              "28                                [11654135, 8298420]  \n",
              "29      [4448313, 4448275, 4447066, 4446456, 4446231]  "
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "users = pd.read_sql(\"\"\"\n",
        "  SELECT\n",
        "    *\n",
        "  FROM \"hacker_news\".\"users\" a\n",
        "  Limit 40\n",
        "\"\"\", engine)\n",
        "\n",
        "users.head(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# WORD 2 VEC TRAINING etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci2ntAd7zdHr",
        "outputId": "227cc148-3dd3-48c0-c46c-4d7f38bb5210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corpus sample:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-14 17:21:29,548 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=128, alpha=0.05>', 'datetime': '2025-04-14T17:21:29.548865', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
            "2025-04-14 17:21:29,550 : INFO : collecting all words and their counts\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunk 1: anarchism originated as a term...\n",
            "Chunk 2: the diggers of the english...\n",
            "Chunk 3: the term is still used...\n",
            "\n",
            "Building vocabulary...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-14 17:21:31,072 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2025-04-14 17:21:31,121 : INFO : PROGRESS: at sentence #10000, processed 150000 words, keeping 15623 word types\n",
            "2025-04-14 17:21:31,171 : INFO : PROGRESS: at sentence #20000, processed 300000 words, keeping 24537 word types\n",
            "2025-04-14 17:21:31,229 : INFO : PROGRESS: at sentence #30000, processed 450000 words, keeping 31556 word types\n",
            "2025-04-14 17:21:31,285 : INFO : PROGRESS: at sentence #40000, processed 600000 words, keeping 38116 word types\n",
            "2025-04-14 17:21:31,335 : INFO : PROGRESS: at sentence #50000, processed 750000 words, keeping 43409 word types\n",
            "2025-04-14 17:21:31,393 : INFO : PROGRESS: at sentence #60000, processed 900000 words, keeping 49078 word types\n",
            "2025-04-14 17:21:31,452 : INFO : PROGRESS: at sentence #70000, processed 1050000 words, keeping 54313 word types\n",
            "2025-04-14 17:21:31,512 : INFO : PROGRESS: at sentence #80000, processed 1200000 words, keeping 58880 word types\n",
            "2025-04-14 17:21:31,568 : INFO : PROGRESS: at sentence #90000, processed 1350000 words, keeping 62226 word types\n",
            "2025-04-14 17:21:31,623 : INFO : PROGRESS: at sentence #100000, processed 1500000 words, keeping 65588 word types\n",
            "2025-04-14 17:21:31,665 : INFO : PROGRESS: at sentence #110000, processed 1650000 words, keeping 69635 word types\n",
            "2025-04-14 17:21:31,731 : INFO : PROGRESS: at sentence #120000, processed 1800000 words, keeping 73452 word types\n",
            "2025-04-14 17:21:31,793 : INFO : PROGRESS: at sentence #130000, processed 1950000 words, keeping 77029 word types\n",
            "2025-04-14 17:21:31,856 : INFO : PROGRESS: at sentence #140000, processed 2100000 words, keeping 80338 word types\n",
            "2025-04-14 17:21:31,905 : INFO : PROGRESS: at sentence #150000, processed 2250000 words, keeping 83123 word types\n",
            "2025-04-14 17:21:31,962 : INFO : PROGRESS: at sentence #160000, processed 2400000 words, keeping 86403 word types\n",
            "2025-04-14 17:21:32,021 : INFO : PROGRESS: at sentence #170000, processed 2550000 words, keeping 89044 word types\n",
            "2025-04-14 17:21:32,086 : INFO : PROGRESS: at sentence #180000, processed 2700000 words, keeping 91907 word types\n",
            "2025-04-14 17:21:32,135 : INFO : PROGRESS: at sentence #190000, processed 2850000 words, keeping 94098 word types\n",
            "2025-04-14 17:21:32,190 : INFO : PROGRESS: at sentence #200000, processed 3000000 words, keeping 96644 word types\n",
            "2025-04-14 17:21:32,234 : INFO : PROGRESS: at sentence #210000, processed 3150000 words, keeping 98740 word types\n",
            "2025-04-14 17:21:32,285 : INFO : PROGRESS: at sentence #220000, processed 3300000 words, keeping 101045 word types\n",
            "2025-04-14 17:21:32,340 : INFO : PROGRESS: at sentence #230000, processed 3450000 words, keeping 103496 word types\n",
            "2025-04-14 17:21:32,396 : INFO : PROGRESS: at sentence #240000, processed 3600000 words, keeping 105927 word types\n",
            "2025-04-14 17:21:32,448 : INFO : PROGRESS: at sentence #250000, processed 3750000 words, keeping 108148 word types\n",
            "2025-04-14 17:21:32,506 : INFO : PROGRESS: at sentence #260000, processed 3900000 words, keeping 110213 word types\n",
            "2025-04-14 17:21:32,556 : INFO : PROGRESS: at sentence #270000, processed 4050000 words, keeping 112038 word types\n",
            "2025-04-14 17:21:32,606 : INFO : PROGRESS: at sentence #280000, processed 4200000 words, keeping 114207 word types\n",
            "2025-04-14 17:21:32,664 : INFO : PROGRESS: at sentence #290000, processed 4350000 words, keeping 116329 word types\n",
            "2025-04-14 17:21:32,704 : INFO : PROGRESS: at sentence #300000, processed 4500000 words, keeping 118751 word types\n",
            "2025-04-14 17:21:32,761 : INFO : PROGRESS: at sentence #310000, processed 4650000 words, keeping 120549 word types\n",
            "2025-04-14 17:21:32,803 : INFO : PROGRESS: at sentence #320000, processed 4800000 words, keeping 122454 word types\n",
            "2025-04-14 17:21:32,860 : INFO : PROGRESS: at sentence #330000, processed 4950000 words, keeping 124634 word types\n",
            "2025-04-14 17:21:32,918 : INFO : PROGRESS: at sentence #340000, processed 5100000 words, keeping 127341 word types\n",
            "2025-04-14 17:21:32,979 : INFO : PROGRESS: at sentence #350000, processed 5250000 words, keeping 129860 word types\n",
            "2025-04-14 17:21:33,032 : INFO : PROGRESS: at sentence #360000, processed 5400000 words, keeping 131762 word types\n",
            "2025-04-14 17:21:33,098 : INFO : PROGRESS: at sentence #370000, processed 5550000 words, keeping 133719 word types\n",
            "2025-04-14 17:21:33,155 : INFO : PROGRESS: at sentence #380000, processed 5700000 words, keeping 135946 word types\n",
            "2025-04-14 17:21:33,211 : INFO : PROGRESS: at sentence #390000, processed 5850000 words, keeping 137784 word types\n",
            "2025-04-14 17:21:33,255 : INFO : PROGRESS: at sentence #400000, processed 6000000 words, keeping 139565 word types\n",
            "2025-04-14 17:21:33,304 : INFO : PROGRESS: at sentence #410000, processed 6150000 words, keeping 141324 word types\n",
            "2025-04-14 17:21:33,355 : INFO : PROGRESS: at sentence #420000, processed 6300000 words, keeping 142942 word types\n",
            "2025-04-14 17:21:33,411 : INFO : PROGRESS: at sentence #430000, processed 6450000 words, keeping 145020 word types\n",
            "2025-04-14 17:21:33,460 : INFO : PROGRESS: at sentence #440000, processed 6600000 words, keeping 147104 word types\n",
            "2025-04-14 17:21:33,526 : INFO : PROGRESS: at sentence #450000, processed 6750000 words, keeping 148645 word types\n",
            "2025-04-14 17:21:33,576 : INFO : PROGRESS: at sentence #460000, processed 6900000 words, keeping 150771 word types\n",
            "2025-04-14 17:21:33,617 : INFO : PROGRESS: at sentence #470000, processed 7050000 words, keeping 152586 word types\n",
            "2025-04-14 17:21:33,650 : INFO : PROGRESS: at sentence #480000, processed 7200000 words, keeping 154420 word types\n",
            "2025-04-14 17:21:33,699 : INFO : PROGRESS: at sentence #490000, processed 7350000 words, keeping 156039 word types\n",
            "2025-04-14 17:21:33,750 : INFO : PROGRESS: at sentence #500000, processed 7500000 words, keeping 158045 word types\n",
            "2025-04-14 17:21:33,813 : INFO : PROGRESS: at sentence #510000, processed 7650000 words, keeping 159770 word types\n",
            "2025-04-14 17:21:33,877 : INFO : PROGRESS: at sentence #520000, processed 7800000 words, keeping 161751 word types\n",
            "2025-04-14 17:21:33,937 : INFO : PROGRESS: at sentence #530000, processed 7950000 words, keeping 163666 word types\n",
            "2025-04-14 17:21:33,991 : INFO : PROGRESS: at sentence #540000, processed 8100000 words, keeping 165975 word types\n",
            "2025-04-14 17:21:34,045 : INFO : PROGRESS: at sentence #550000, processed 8250000 words, keeping 167972 word types\n",
            "2025-04-14 17:21:34,095 : INFO : PROGRESS: at sentence #560000, processed 8400000 words, keeping 169882 word types\n",
            "2025-04-14 17:21:34,155 : INFO : PROGRESS: at sentence #570000, processed 8550000 words, keeping 171797 word types\n",
            "2025-04-14 17:21:34,203 : INFO : PROGRESS: at sentence #580000, processed 8700000 words, keeping 173432 word types\n",
            "2025-04-14 17:21:34,274 : INFO : PROGRESS: at sentence #590000, processed 8850000 words, keeping 175076 word types\n",
            "2025-04-14 17:21:34,323 : INFO : PROGRESS: at sentence #600000, processed 9000000 words, keeping 178162 word types\n",
            "2025-04-14 17:21:34,380 : INFO : PROGRESS: at sentence #610000, processed 9150000 words, keeping 180549 word types\n",
            "2025-04-14 17:21:34,440 : INFO : PROGRESS: at sentence #620000, processed 9300000 words, keeping 181974 word types\n",
            "2025-04-14 17:21:34,489 : INFO : PROGRESS: at sentence #630000, processed 9450000 words, keeping 183788 word types\n",
            "2025-04-14 17:21:34,539 : INFO : PROGRESS: at sentence #640000, processed 9600000 words, keeping 184985 word types\n",
            "2025-04-14 17:21:34,603 : INFO : PROGRESS: at sentence #650000, processed 9750000 words, keeping 186406 word types\n",
            "2025-04-14 17:21:34,658 : INFO : PROGRESS: at sentence #660000, processed 9900000 words, keeping 188097 word types\n",
            "2025-04-14 17:21:34,700 : INFO : PROGRESS: at sentence #670000, processed 10050000 words, keeping 189701 word types\n",
            "2025-04-14 17:21:34,750 : INFO : PROGRESS: at sentence #680000, processed 10200000 words, keeping 191293 word types\n",
            "2025-04-14 17:21:34,800 : INFO : PROGRESS: at sentence #690000, processed 10350000 words, keeping 193065 word types\n",
            "2025-04-14 17:21:34,859 : INFO : PROGRESS: at sentence #700000, processed 10500000 words, keeping 194510 word types\n",
            "2025-04-14 17:21:34,912 : INFO : PROGRESS: at sentence #710000, processed 10650000 words, keeping 195761 word types\n",
            "2025-04-14 17:21:34,966 : INFO : PROGRESS: at sentence #720000, processed 10800000 words, keeping 197082 word types\n",
            "2025-04-14 17:21:35,000 : INFO : PROGRESS: at sentence #730000, processed 10950000 words, keeping 198428 word types\n",
            "2025-04-14 17:21:35,049 : INFO : PROGRESS: at sentence #740000, processed 11100000 words, keeping 199591 word types\n",
            "2025-04-14 17:21:35,090 : INFO : PROGRESS: at sentence #750000, processed 11250000 words, keeping 201183 word types\n",
            "2025-04-14 17:21:35,123 : INFO : PROGRESS: at sentence #760000, processed 11400000 words, keeping 202399 word types\n",
            "2025-04-14 17:21:35,165 : INFO : PROGRESS: at sentence #770000, processed 11550000 words, keeping 203804 word types\n",
            "2025-04-14 17:21:35,214 : INFO : PROGRESS: at sentence #780000, processed 11700000 words, keeping 205412 word types\n",
            "2025-04-14 17:21:35,253 : INFO : PROGRESS: at sentence #790000, processed 11850000 words, keeping 206671 word types\n",
            "2025-04-14 17:21:35,297 : INFO : PROGRESS: at sentence #800000, processed 12000000 words, keeping 207894 word types\n",
            "2025-04-14 17:21:35,346 : INFO : PROGRESS: at sentence #810000, processed 12150000 words, keeping 209427 word types\n",
            "2025-04-14 17:21:35,387 : INFO : PROGRESS: at sentence #820000, processed 12300000 words, keeping 210874 word types\n",
            "2025-04-14 17:21:35,429 : INFO : PROGRESS: at sentence #830000, processed 12450000 words, keeping 212382 word types\n",
            "2025-04-14 17:21:35,469 : INFO : PROGRESS: at sentence #840000, processed 12600000 words, keeping 213476 word types\n",
            "2025-04-14 17:21:35,510 : INFO : PROGRESS: at sentence #850000, processed 12750000 words, keeping 214712 word types\n",
            "2025-04-14 17:21:35,560 : INFO : PROGRESS: at sentence #860000, processed 12900000 words, keeping 216370 word types\n",
            "2025-04-14 17:21:35,609 : INFO : PROGRESS: at sentence #870000, processed 13050000 words, keeping 217660 word types\n",
            "2025-04-14 17:21:35,643 : INFO : PROGRESS: at sentence #880000, processed 13200000 words, keeping 218961 word types\n",
            "2025-04-14 17:21:35,690 : INFO : PROGRESS: at sentence #890000, processed 13350000 words, keeping 220143 word types\n",
            "2025-04-14 17:21:35,733 : INFO : PROGRESS: at sentence #900000, processed 13500000 words, keeping 221415 word types\n",
            "2025-04-14 17:21:35,784 : INFO : PROGRESS: at sentence #910000, processed 13650000 words, keeping 222720 word types\n",
            "2025-04-14 17:21:35,823 : INFO : PROGRESS: at sentence #920000, processed 13800000 words, keeping 224357 word types\n",
            "2025-04-14 17:21:35,858 : INFO : PROGRESS: at sentence #930000, processed 13950000 words, keeping 226138 word types\n",
            "2025-04-14 17:21:35,903 : INFO : PROGRESS: at sentence #940000, processed 14100000 words, keeping 228041 word types\n",
            "2025-04-14 17:21:35,940 : INFO : PROGRESS: at sentence #950000, processed 14250000 words, keeping 229253 word types\n",
            "2025-04-14 17:21:35,981 : INFO : PROGRESS: at sentence #960000, processed 14400000 words, keeping 230554 word types\n",
            "2025-04-14 17:21:36,022 : INFO : PROGRESS: at sentence #970000, processed 14550000 words, keeping 231808 word types\n",
            "2025-04-14 17:21:36,065 : INFO : PROGRESS: at sentence #980000, processed 14700000 words, keeping 233763 word types\n",
            "2025-04-14 17:21:36,106 : INFO : PROGRESS: at sentence #990000, processed 14850000 words, keeping 235578 word types\n",
            "2025-04-14 17:21:36,147 : INFO : PROGRESS: at sentence #1000000, processed 15000000 words, keeping 237390 word types\n",
            "2025-04-14 17:21:36,186 : INFO : PROGRESS: at sentence #1010000, processed 15150000 words, keeping 238619 word types\n",
            "2025-04-14 17:21:36,226 : INFO : PROGRESS: at sentence #1020000, processed 15300000 words, keeping 239952 word types\n",
            "2025-04-14 17:21:36,268 : INFO : PROGRESS: at sentence #1030000, processed 15450000 words, keeping 241284 word types\n",
            "2025-04-14 17:21:36,310 : INFO : PROGRESS: at sentence #1040000, processed 15600000 words, keeping 242448 word types\n",
            "2025-04-14 17:21:36,358 : INFO : PROGRESS: at sentence #1050000, processed 15750000 words, keeping 243745 word types\n",
            "2025-04-14 17:21:36,400 : INFO : PROGRESS: at sentence #1060000, processed 15900000 words, keeping 244769 word types\n",
            "2025-04-14 17:21:36,441 : INFO : PROGRESS: at sentence #1070000, processed 16050000 words, keeping 245997 word types\n",
            "2025-04-14 17:21:36,481 : INFO : PROGRESS: at sentence #1080000, processed 16200000 words, keeping 247195 word types\n",
            "2025-04-14 17:21:36,524 : INFO : PROGRESS: at sentence #1090000, processed 16350000 words, keeping 248350 word types\n",
            "2025-04-14 17:21:36,566 : INFO : PROGRESS: at sentence #1100000, processed 16500000 words, keeping 249620 word types\n",
            "2025-04-14 17:21:36,611 : INFO : PROGRESS: at sentence #1110000, processed 16650000 words, keeping 250750 word types\n",
            "2025-04-14 17:21:36,664 : INFO : PROGRESS: at sentence #1120000, processed 16800000 words, keeping 252427 word types\n",
            "2025-04-14 17:21:36,720 : INFO : PROGRESS: at sentence #1130000, processed 16950000 words, keeping 253541 word types\n",
            "2025-04-14 17:21:36,990 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1133681 sentences\n",
            "2025-04-14 17:21:36,990 : INFO : Creating a fresh vocabulary\n",
            "2025-04-14 17:21:37,182 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=20 retains 31892 unique words (12.56% of original 253854, drops 221962)', 'datetime': '2025-04-14T17:21:37.182994', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
            "2025-04-14 17:21:37,182 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=20 leaves 16354036 word corpus (96.17% of original 17005207, drops 651171)', 'datetime': '2025-04-14T17:21:37.182994', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
            "2025-04-14 17:21:37,386 : INFO : deleting the raw counts dictionary of 253854 items\n",
            "2025-04-14 17:21:37,448 : INFO : sample=1e-05 downsamples 3918 most-common words\n",
            "2025-04-14 17:21:37,448 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 5166157.75386049 word corpus (31.6%% of prior 16354036)', 'datetime': '2025-04-14T17:21:37.448649', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
            "2025-04-14 17:21:37,736 : INFO : estimated required memory for 31892 words and 128 dimensions: 48603408 bytes\n",
            "2025-04-14 17:21:37,736 : INFO : resetting layer weights\n",
            "2025-04-14 17:21:37,760 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-14T17:21:37.760637', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
            "2025-04-14 17:21:37,760 : INFO : Word2Vec lifecycle event {'msg': 'training model with 16 workers on 31892 vocabulary and 128 features, using sg=0 hs=0 sample=1e-05 negative=10 window=10 shrink_windows=True', 'datetime': '2025-04-14T17:21:37.760637', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-14 17:21:39,278 : INFO : EPOCH 0 - PROGRESS: at 0.06% examples, 2221 words/s, in_qsize 32, out_qsize 0\n",
            "2025-04-14 17:21:52,346 : INFO : EPOCH 0: training on 17005207 raw words (5165872 effective words) took 14.6s, 354419 effective words/s\n",
            "2025-04-14 17:21:54,081 : INFO : EPOCH 1 - PROGRESS: at 0.06% examples, 1926 words/s, in_qsize 32, out_qsize 0\n",
            "2025-04-14 17:22:06,493 : INFO : EPOCH 1: training on 17005207 raw words (5164777 effective words) took 14.1s, 365299 effective words/s\n",
            "2025-04-14 17:22:08,058 : INFO : EPOCH 2 - PROGRESS: at 0.06% examples, 2113 words/s, in_qsize 32, out_qsize 0\n",
            "2025-04-14 17:22:21,285 : INFO : EPOCH 2: training on 17005207 raw words (5164797 effective words) took 14.8s, 349146 effective words/s\n",
            "2025-04-14 17:22:23,046 : INFO : EPOCH 3 - PROGRESS: at 0.06% examples, 1953 words/s, in_qsize 30, out_qsize 0\n",
            "2025-04-14 17:22:35,694 : INFO : EPOCH 3: training on 17005207 raw words (5166716 effective words) took 14.4s, 358851 effective words/s\n",
            "2025-04-14 17:22:37,377 : INFO : EPOCH 4 - PROGRESS: at 0.06% examples, 2014 words/s, in_qsize 17, out_qsize 0\n",
            "2025-04-14 17:22:50,785 : INFO : EPOCH 4: training on 17005207 raw words (5167168 effective words) took 15.1s, 342620 effective words/s\n",
            "2025-04-14 17:22:52,382 : INFO : EPOCH 5 - PROGRESS: at 0.06% examples, 2089 words/s, in_qsize 32, out_qsize 0\n",
            "2025-04-14 17:23:05,208 : INFO : EPOCH 5: training on 17005207 raw words (5165296 effective words) took 14.4s, 358422 effective words/s\n",
            "2025-04-14 17:23:07,404 : INFO : EPOCH 6 - PROGRESS: at 0.06% examples, 1551 words/s, in_qsize 32, out_qsize 0\n",
            "2025-04-14 17:23:20,004 : INFO : EPOCH 6: training on 17005207 raw words (5166250 effective words) took 14.8s, 349324 effective words/s\n",
            "2025-04-14 17:23:21,727 : INFO : EPOCH 7 - PROGRESS: at 0.06% examples, 1856 words/s, in_qsize 13, out_qsize 0\n",
            "2025-04-14 17:23:35,413 : INFO : EPOCH 7: training on 17005207 raw words (5167138 effective words) took 15.4s, 335556 effective words/s\n",
            "2025-04-14 17:23:36,926 : INFO : EPOCH 8 - PROGRESS: at 0.06% examples, 2243 words/s, in_qsize 31, out_qsize 0\n",
            "2025-04-14 17:23:49,510 : INFO : EPOCH 8: training on 17005207 raw words (5166023 effective words) took 14.1s, 366642 effective words/s\n",
            "2025-04-14 17:23:51,107 : INFO : EPOCH 9 - PROGRESS: at 0.06% examples, 2128 words/s, in_qsize 1, out_qsize 0\n",
            "2025-04-14 17:24:04,289 : INFO : EPOCH 9: training on 17005207 raw words (5166432 effective words) took 14.8s, 349791 effective words/s\n",
            "2025-04-14 17:24:06,048 : INFO : EPOCH 10 - PROGRESS: at 0.06% examples, 1919 words/s, in_qsize 22, out_qsize 0\n",
            "2025-04-14 17:24:19,344 : INFO : EPOCH 10: training on 17005207 raw words (5164824 effective words) took 15.0s, 343184 effective words/s\n",
            "2025-04-14 17:24:21,128 : INFO : EPOCH 11 - PROGRESS: at 0.06% examples, 1874 words/s, in_qsize 3, out_qsize 0\n",
            "2025-04-14 17:24:33,823 : INFO : EPOCH 11: training on 17005207 raw words (5165817 effective words) took 14.5s, 357104 effective words/s\n",
            "2025-04-14 17:24:35,651 : INFO : EPOCH 12 - PROGRESS: at 0.06% examples, 1849 words/s, in_qsize 32, out_qsize 0\n",
            "2025-04-14 17:24:49,477 : INFO : EPOCH 12: training on 17005207 raw words (5165202 effective words) took 15.6s, 330121 effective words/s\n",
            "2025-04-14 17:24:51,170 : INFO : EPOCH 13 - PROGRESS: at 0.06% examples, 1975 words/s, in_qsize 17, out_qsize 0\n",
            "2025-04-14 17:25:04,288 : INFO : EPOCH 13: training on 17005207 raw words (5166472 effective words) took 14.8s, 348901 effective words/s\n",
            "2025-04-14 17:25:06,124 : INFO : EPOCH 14 - PROGRESS: at 0.06% examples, 1873 words/s, in_qsize 32, out_qsize 0\n",
            "2025-04-14 17:25:19,911 : INFO : EPOCH 14: training on 17005207 raw words (5166051 effective words) took 15.6s, 331020 effective words/s\n",
            "2025-04-14 17:25:19,911 : INFO : Word2Vec lifecycle event {'msg': 'training on 255078105 raw words (77488835 effective words) took 222.2s, 348812 effective words/s', 'datetime': '2025-04-14T17:25:19.911189', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training complete. Vocab size: 31892\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "class Text8Corpus:\n",
        "    \"\"\"Proper iterator for text8 format (one giant line of space-separated words)\"\"\"\n",
        "    def __iter__(self):\n",
        "        with open('text8.txt', 'r', encoding='utf-8') as f:\n",
        "            # Read the entire file (it's one line)\n",
        "            text = f.read().strip()\n",
        "            words = text.split()\n",
        "            \n",
        "            # Yield chunks as \"sentences\" (100 words each)\n",
        "            chunk_size = 15\n",
        "            for i in range(0, len(words), chunk_size):\n",
        "                yield words[i:i + chunk_size]\n",
        "\n",
        "# Verify the corpus\n",
        "print(\"Corpus sample:\")\n",
        "corpus = Text8Corpus()\n",
        "for i, sentence in enumerate(corpus):\n",
        "    print(f\"Chunk {i+1}: {' '.join(sentence[:5])}...\")  # First 5 words\n",
        "    if i >= 2:  # Show just 3 samples\n",
        "        break\n",
        "\n",
        "# Initialize model with optimized settings\n",
        "initial_model = Word2Vec(\n",
        "    vector_size=128,\n",
        "    window=10,          # Larger window for document-style text\n",
        "    min_count=20,       # Ignore very rare words\n",
        "    workers=os.cpu_count(),\n",
        "    sg=0,               # CBOW often works better for large corpora\n",
        "    negative=10,        # Negative sampling\n",
        "    hs=0,               # Disable hierarchical softmax\n",
        "    epochs=15,          # More epochs for better quality\n",
        "    sample=1e-5,        # Aggressive downsampling\n",
        "    alpha=0.05,         # Higher initial learning rate\n",
        "    min_alpha=0.0001    # Final learning rate\n",
        ")\n",
        "\n",
        "# Build vocabulary\n",
        "print(\"\\nBuilding vocabulary...\")\n",
        "initial_model.build_vocab(corpus)\n",
        "\n",
        "# Train model\n",
        "print(\"Training model...\")\n",
        "initial_model.train(\n",
        "    corpus,\n",
        "    total_examples=initial_model.corpus_count,\n",
        "    epochs=initial_model.epochs,\n",
        "    compute_loss=True,\n",
        "    report_delay=60\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining complete. Vocab size: {len(initial_model.wv)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl1fOCCn0rw3",
        "outputId": "9bce73bd-0d0e-46fc-d9f0-9f34fdeef9d4"
      },
      "outputs": [],
      "source": [
        "import difflib\n",
        "\n",
        "def check_semantics_with_fallback(model, word):\n",
        "    if not word.strip():  # Check for empty input\n",
        "        print(\"Word cannot be empty.\")\n",
        "        return\n",
        "\n",
        "    if word in model.wv:  # If the word exists in the vocabulary\n",
        "        print(f\"\\nMost similar to '{word}':\")\n",
        "        for similar, score in model.wv.most_similar(word, topn=5):\n",
        "            print(f\"{similar}: {score:.3f}\")\n",
        "    else:  # If the word is not in the vocabulary\n",
        "        print(f\"'{word}' not in vocabulary.\")\n",
        "        # Find similar words using difflib\n",
        "        vocab = model.wv.index_to_key\n",
        "        suggestions = difflib.get_close_matches(word, vocab, n=5, cutoff=0.6)\n",
        "        if suggestions:\n",
        "            print(f\"Did you mean: {', '.join(suggestions)}?\")\n",
        "            # Use the first suggestion to find similar words\n",
        "            fallback_word = suggestions[0]\n",
        "            print(f\"\\nFalling back to '{fallback_word}':\")\n",
        "            for similar, score in model.wv.most_similar(fallback_word, topn=5):\n",
        "                print(f\"{similar}: {score:.3f}\")\n",
        "        else:\n",
        "            print(\"No similar words found in the vocabulary.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VenFCNVk1weC",
        "outputId": "d887863c-f2c5-4325-8f66-088ab619b7c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Most similar to 'computer':\n",
            "computers: 0.725\n",
            "supercomputers: 0.668\n",
            "hardware: 0.650\n",
            "bootstrap: 0.637\n",
            "computing: 0.630\n",
            "\n",
            "Most similar to 'freedom':\n",
            "freedoms: 0.644\n",
            "liberty: 0.576\n",
            "rights: 0.566\n",
            "liberties: 0.551\n",
            "equality: 0.526\n",
            "\n",
            "Most similar to 'anarchy':\n",
            "capitalism: 0.611\n",
            "collectivism: 0.538\n",
            "anarcho: 0.534\n",
            "anarchism: 0.522\n",
            "chaos: 0.521\n",
            "'worldl' not in vocabulary.\n",
            "Did you mean: worldly, world, worlds, wordle, word?\n",
            "\n",
            "Falling back to 'worldly':\n",
            "humility: 0.595\n",
            "piety: 0.569\n",
            "nonviolence: 0.569\n",
            "spiritual: 0.566\n",
            "conceives: 0.565\n",
            "'nonexistentword' not in vocabulary.\n",
            "Did you mean: nonexistent, existent, inconsistent, consistent, existed?\n",
            "\n",
            "Falling back to 'nonexistent':\n",
            "unusable: 0.431\n",
            "inflated: 0.427\n",
            "reliable: 0.427\n",
            "unreliable: 0.414\n",
            "credible: 0.403\n"
          ]
        }
      ],
      "source": [
        "# Words to test\n",
        "words_to_test = [\"computer\", \"freedom\", \"anarchy\", \"worldl\", \"nonexistentword\"]\n",
        "\n",
        "# Run the function for each word\n",
        "for word in words_to_test:\n",
        "    check_semantics_with_fallback(initial_model, word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Fine-tune the model with post titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                             Ikiwiki: A Wiki Compiler\n",
            "1    Show HN: A collection of shell/Terraform scrip...\n",
            "2    Ask HN: Let's collate system outages caused by...\n",
            "3    Taking Back the Web with Decentralization: 202...\n",
            "4                Stuff we figured out about AI in 2023\n",
            "Name: title, dtype: object\n",
            "[['ikiwiki', 'wiki', 'compiler'], ['show_hn', 'collection', 'of', 'shell', 'terraform', 'scripts', 'to', 'host', 'web', 'site', 'on', 'aws'], ['ask_hn', 'let', 'collate', 'system', 'outages', 'caused', 'by', 'expiring', 'certs'], ['taking', 'back', 'the', 'web', 'with', 'in', 'review'], ['stuff', 'we', 'figured', 'out', 'about', 'ai', 'in']]\n"
          ]
        }
      ],
      "source": [
        "titles = res.title\n",
        "titles\n",
        "\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# Preprocess titles to match text8 style\n",
        "def preprocess_hn_title(title):\n",
        "    title = str(title).lower()\n",
        "    title = title.replace(\"show hn:\", \" show_hn \")  # preserve special markers\n",
        "    title = title.replace(\"ask hn:\", \" ask_hn \")\n",
        "    return simple_preprocess(title)  # remove punctuation\n",
        "\n",
        "# Create training sentences\n",
        "sentences = [preprocess_hn_title(title) for title in titles if title and len(title) > 0]\n",
        "\n",
        "print(titles[:5])\n",
        "print(sentences[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample preprocessed titles:\n",
            "Original: Ikiwiki: A Wiki Compiler\n",
            "Processed: ['ikiwiki', 'wiki', 'compiler']\n",
            "\n",
            "Original: Show HN: A collection of shell/Terraform scripts to host a web site on AWS\n",
            "Processed: ['show_hn', 'collection', 'of', 'shell', 'terraform', 'scripts', 'to', 'host', 'web', 'site', 'on', 'aws']\n",
            "\n",
            "Original: Ask HN: Let's collate system outages caused by expiring certs\n",
            "Processed: ['ask_hn', 'let', 'collate', 'system', 'outages', 'caused', 'by', 'expiring', 'certs']\n",
            "\n",
            "Original: Taking Back the Web with Decentralization: 2023 in Review\n",
            "Processed: ['taking', 'back', 'the', 'web', 'with', 'in', 'review']\n",
            "\n",
            "Original: Stuff we figured out about AI in 2023\n",
            "Processed: ['stuff', 'we', 'figured', 'out', 'about', 'ai', 'in']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Sample preprocessed titles:\")\n",
        "for i in range(5):\n",
        "    print(f\"Original: {titles.iloc[i]}\")\n",
        "    print(f\"Processed: {sentences[i]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-14 17:26:26,451 : INFO : collecting all words and their counts\n",
            "2025-04-14 17:26:26,453 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2025-04-14 17:26:26,469 : INFO : PROGRESS: at sentence #10000, processed 76198 words, keeping 13693 word types\n",
            "2025-04-14 17:26:26,490 : INFO : PROGRESS: at sentence #20000, processed 153103 words, keeping 19994 word types\n",
            "2025-04-14 17:26:26,524 : INFO : PROGRESS: at sentence #30000, processed 230467 words, keeping 25104 word types\n",
            "2025-04-14 17:26:26,551 : INFO : PROGRESS: at sentence #40000, processed 307506 words, keeping 29227 word types\n",
            "2025-04-14 17:26:26,597 : INFO : PROGRESS: at sentence #50000, processed 385256 words, keeping 32646 word types\n",
            "2025-04-14 17:26:26,639 : INFO : PROGRESS: at sentence #60000, processed 462945 words, keeping 35889 word types\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original vocab size: 31892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-14 17:26:26,673 : INFO : PROGRESS: at sentence #70000, processed 541435 words, keeping 38953 word types\n",
            "2025-04-14 17:26:26,714 : INFO : PROGRESS: at sentence #80000, processed 619761 words, keeping 41715 word types\n",
            "2025-04-14 17:26:26,751 : INFO : PROGRESS: at sentence #90000, processed 698036 words, keeping 44448 word types\n",
            "2025-04-14 17:26:26,779 : INFO : PROGRESS: at sentence #100000, processed 776241 words, keeping 46887 word types\n",
            "2025-04-14 17:26:26,808 : INFO : PROGRESS: at sentence #110000, processed 854390 words, keeping 49109 word types\n",
            "2025-04-14 17:26:26,838 : INFO : PROGRESS: at sentence #120000, processed 932739 words, keeping 51271 word types\n",
            "2025-04-14 17:26:26,855 : INFO : PROGRESS: at sentence #130000, processed 1010951 words, keeping 53438 word types\n",
            "2025-04-14 17:26:26,880 : INFO : PROGRESS: at sentence #140000, processed 1089176 words, keeping 55463 word types\n",
            "2025-04-14 17:26:26,909 : INFO : PROGRESS: at sentence #150000, processed 1167762 words, keeping 57422 word types\n",
            "2025-04-14 17:26:26,934 : INFO : PROGRESS: at sentence #160000, processed 1245955 words, keeping 59442 word types\n",
            "2025-04-14 17:26:26,959 : INFO : PROGRESS: at sentence #170000, processed 1323873 words, keeping 61318 word types\n",
            "2025-04-14 17:26:26,990 : INFO : PROGRESS: at sentence #180000, processed 1401839 words, keeping 63180 word types\n",
            "2025-04-14 17:26:27,020 : INFO : PROGRESS: at sentence #190000, processed 1480192 words, keeping 65044 word types\n",
            "2025-04-14 17:26:27,053 : INFO : PROGRESS: at sentence #200000, processed 1558916 words, keeping 66862 word types\n",
            "2025-04-14 17:26:27,086 : INFO : PROGRESS: at sentence #210000, processed 1637488 words, keeping 68623 word types\n",
            "2025-04-14 17:26:27,128 : INFO : PROGRESS: at sentence #220000, processed 1716153 words, keeping 70319 word types\n",
            "2025-04-14 17:26:27,169 : INFO : PROGRESS: at sentence #230000, processed 1793787 words, keeping 72027 word types\n",
            "2025-04-14 17:26:27,176 : INFO : collected 72332 word types from a corpus of 1808102 raw words and 231822 sentences\n",
            "2025-04-14 17:26:27,176 : INFO : Updating model with new vocabulary\n",
            "2025-04-14 17:26:27,407 : INFO : Word2Vec lifecycle event {'msg': 'added 1171 new unique words (1.62% of original 72332) and increased the count of 7638 pre-existing words (10.56% of original 72332)', 'datetime': '2025-04-14T17:26:27.407697', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
            "2025-04-14 17:26:27,483 : INFO : deleting the raw counts dictionary of 72332 items\n",
            "2025-04-14 17:26:27,487 : INFO : sample=1e-05 downsamples 5146 most-common words\n",
            "2025-04-14 17:26:27,490 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 459719.75425014156 word corpus (28.5%% of prior 1614824)', 'datetime': '2025-04-14T17:26:27.490305', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
            "2025-04-14 17:26:27,754 : INFO : estimated required memory for 8809 words and 128 dimensions: 13424916 bytes\n",
            "2025-04-14 17:26:27,754 : INFO : updating layer weights\n",
            "2025-04-14 17:26:27,795 : INFO : Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2025-04-14T17:26:27.795379', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
            "2025-04-14 17:26:27,799 : WARNING : Effective 'alpha' higher than previous training cycles\n",
            "2025-04-14 17:26:27,799 : INFO : Word2Vec lifecycle event {'msg': 'training model with 16 workers on 33063 vocabulary and 128 features, using sg=0 hs=0 sample=1e-05 negative=10 window=10 shrink_windows=True', 'datetime': '2025-04-14T17:26:27.799254', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New vocab size: 33063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-14 17:26:28,847 : INFO : EPOCH 0 - PROGRESS: at 76.98% examples, 419679 words/s, in_qsize 31, out_qsize 0\n",
            "2025-04-14 17:26:29,069 : INFO : EPOCH 0: training on 1808102 raw words (547330 effective words) took 1.2s, 447871 effective words/s\n",
            "2025-04-14 17:26:30,089 : INFO : EPOCH 1 - PROGRESS: at 73.08% examples, 393121 words/s, in_qsize 29, out_qsize 2\n",
            "2025-04-14 17:26:30,317 : INFO : EPOCH 1: training on 1808102 raw words (547058 effective words) took 1.2s, 440477 effective words/s\n",
            "2025-04-14 17:26:31,377 : INFO : EPOCH 2 - PROGRESS: at 83.56% examples, 453227 words/s, in_qsize 30, out_qsize 0\n",
            "2025-04-14 17:26:31,509 : INFO : EPOCH 2: training on 1808102 raw words (546277 effective words) took 1.1s, 481502 effective words/s\n",
            "2025-04-14 17:26:32,526 : INFO : EPOCH 3 - PROGRESS: at 81.37% examples, 440673 words/s, in_qsize 30, out_qsize 1\n",
            "2025-04-14 17:26:32,689 : INFO : EPOCH 3: training on 1808102 raw words (546083 effective words) took 1.2s, 469067 effective words/s\n",
            "2025-04-14 17:26:33,705 : INFO : EPOCH 4 - PROGRESS: at 75.87% examples, 412961 words/s, in_qsize 30, out_qsize 1\n",
            "2025-04-14 17:26:33,908 : INFO : EPOCH 4: training on 1808102 raw words (547471 effective words) took 1.2s, 453190 effective words/s\n",
            "2025-04-14 17:26:34,928 : INFO : EPOCH 5 - PROGRESS: at 79.16% examples, 430423 words/s, in_qsize 27, out_qsize 4\n",
            "2025-04-14 17:26:35,099 : INFO : EPOCH 5: training on 1808102 raw words (546689 effective words) took 1.2s, 467264 effective words/s\n",
            "2025-04-14 17:26:36,123 : INFO : EPOCH 6 - PROGRESS: at 82.45% examples, 448231 words/s, in_qsize 32, out_qsize 0\n",
            "2025-04-14 17:26:36,270 : INFO : EPOCH 6: training on 1808102 raw words (546654 effective words) took 1.1s, 475451 effective words/s\n",
            "2025-04-14 17:26:37,296 : INFO : EPOCH 7 - PROGRESS: at 94.00% examples, 513531 words/s, in_qsize 11, out_qsize 1\n",
            "2025-04-14 17:26:37,320 : INFO : EPOCH 7: training on 1808102 raw words (546979 effective words) took 1.0s, 533897 effective words/s\n",
            "2025-04-14 17:26:38,350 : INFO : EPOCH 8 - PROGRESS: at 83.55% examples, 456019 words/s, in_qsize 29, out_qsize 1\n",
            "2025-04-14 17:26:38,491 : INFO : EPOCH 8: training on 1808102 raw words (547038 effective words) took 1.1s, 479380 effective words/s\n",
            "2025-04-14 17:26:39,552 : INFO : EPOCH 9 - PROGRESS: at 88.50% examples, 482579 words/s, in_qsize 18, out_qsize 3\n",
            "2025-04-14 17:26:39,619 : INFO : EPOCH 9: training on 1808102 raw words (546980 effective words) took 1.1s, 512077 effective words/s\n",
            "2025-04-14 17:26:39,619 : INFO : Word2Vec lifecycle event {'msg': 'training on 18081020 raw words (5468559 effective words) took 11.8s, 462703 effective words/s', 'datetime': '2025-04-14T17:26:39.619782', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuning complete. Final loss: 1079099.25\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "# Create a deep copy of the initial model\n",
        "tuned_model = copy.deepcopy(initial_model)\n",
        "\n",
        "# Update vocabulary with HN-specific terms\n",
        "print(f\"Original vocab size: {len(tuned_model.wv)}\")\n",
        "tuned_model.build_vocab(sentences, update=True)  # update=True is crucial\n",
        "print(f\"New vocab size: {len(tuned_model.wv)}\")\n",
        "\n",
        "# Adjust learning rates for fine-tuning\n",
        "tuned_model.alpha = 0.01       # Lower initial rate\n",
        "tuned_model.min_alpha = 0.001  # Higher final rate\n",
        "\n",
        "# Fine-tune the model\n",
        "tuned_model.train(\n",
        "    sentences,\n",
        "    total_examples=len(sentences),\n",
        "    epochs=10,           # More epochs for small dataset\n",
        "    compute_loss=True,\n",
        "    report_delay=1\n",
        ")\n",
        "\n",
        "print(f\"Fine-tuning complete. Final loss: {tuned_model.get_latest_training_loss()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Most similar to 'computer':\n",
            "computers: 0.731\n",
            "computing: 0.701\n",
            "hardware: 0.688\n",
            "homebrew: 0.687\n",
            "bootstrap: 0.657\n",
            "\n",
            "Most similar to 'computer':\n",
            "computers: 0.721\n",
            "computing: 0.703\n",
            "hardware: 0.686\n",
            "homebrew: 0.656\n",
            "bootstrap: 0.628\n",
            "\n",
            "Most similar to 'freedom':\n",
            "freedoms: 0.650\n",
            "liberty: 0.588\n",
            "free: 0.527\n",
            "rights: 0.527\n",
            "liberties: 0.522\n",
            "\n",
            "Most similar to 'freedom':\n",
            "freedoms: 0.638\n",
            "liberty: 0.593\n",
            "rights: 0.525\n",
            "liberties: 0.507\n",
            "equality: 0.505\n",
            "'worldl' not in vocabulary.\n",
            "Did you mean: worldly, world, worlds, word, would?\n",
            "\n",
            "Falling back to 'worldly':\n",
            "philosophic: 0.632\n",
            "humility: 0.589\n",
            "nonviolence: 0.580\n",
            "virtuous: 0.565\n",
            "vices: 0.563\n",
            "'worldl' not in vocabulary.\n",
            "Did you mean: worldly, world, worlds, wordle, word?\n",
            "\n",
            "Falling back to 'worldly':\n",
            "philosophic: 0.632\n",
            "humility: 0.597\n",
            "nonviolence: 0.580\n",
            "virtuous: 0.569\n",
            "vices: 0.567\n",
            "\n",
            "Most similar to 'ai':\n",
            "artificial: 0.499\n",
            "cyc: 0.463\n",
            "sh: 0.462\n",
            "intelligence: 0.430\n",
            "ay: 0.391\n",
            "\n",
            "Most similar to 'ai':\n",
            "chatgpt: 0.574\n",
            "devin: 0.540\n",
            "bot: 0.526\n",
            "cyc: 0.524\n",
            "automate: 0.513\n",
            "'gpt' not in vocabulary.\n",
            "Did you mean: pt, gt, gp, gupta, egypt?\n",
            "\n",
            "Falling back to 'pt':\n",
            "rb: 0.521\n",
            "wt: 0.517\n",
            "lg: 0.513\n",
            "af: 0.512\n",
            "ro: 0.507\n",
            "\n",
            "Most similar to 'gpt':\n",
            "llm: 0.813\n",
            "show_hn: 0.793\n",
            "llms: 0.784\n",
            "chatgpt: 0.784\n",
            "prompts: 0.743\n",
            "'agentic' not in vocabulary.\n",
            "Did you mean: genetic, agent, magnetic, genetics, agnostic?\n",
            "\n",
            "Falling back to 'genetic':\n",
            "chromosomal: 0.677\n",
            "dna: 0.651\n",
            "genetics: 0.644\n",
            "recombinant: 0.634\n",
            "genomic: 0.633\n",
            "\n",
            "Most similar to 'agentic':\n",
            "workflow: 0.785\n",
            "workflows: 0.778\n",
            "llamaindex: 0.765\n",
            "tabular: 0.765\n",
            "benchmarking: 0.763\n"
          ]
        }
      ],
      "source": [
        "# Words to test\n",
        "words_to_test = [\"computer\", \"freedom\", \"worldl\", \"ai\", \"gpt\", \"agentic\"]\n",
        "\n",
        "# Run the function for each word\n",
        "for word in words_to_test:\n",
        "    check_semantics_with_fallback(initial_model, word)\n",
        "    check_semantics_with_fallback(tuned_model, word)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (myenv)",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

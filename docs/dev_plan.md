**Project Plan: "Dropout Disco" Week 1** 🕺💃✨
---

**Overall Goal:** Predict HN upvotes using title embeddings from a custom word2vec model, deployed as a Dockerized FastAPI service. 🐳

**Phase 1: Custom Word Embedding Generation (word2vec)** 🧠

*   **Goal:** Train word embeddings on `text8` and save the resulting vectors.
*   **Environment:** Local machine 💻 (MPS Accelerated)

| Step | Task                                             | Description & Details                                                                                                                                                                                                 | Potential Focus       | Status         | Notes                                                                                                                                                                                                                               |
| :--- | :----------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------- | :------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1.1  | **Setup & Data Acquisition** ⚙️                 | Python env ok ✅. Libs installed ✅. `text8` loaded ✅. Project structure with `utils`, `src` set up ✅. **MPS verified** ✅. **W&B setup** ✅.                                                                        | Team (All) 🤝          | ✅ **Complete** | Environment is ready, data loaded, basic structure in place.                                                                                                                                                                        |
| 1.2  | **Text Preprocessing & Vocabulary** 🧹           | `src/word2vec/vocabulary.py` created ✅. Handles tokenization (via list input), vocab building (`min_freq`, `<UNK>`) ✅. Saves/Loads vocab (`.json`) ✅.                                                               | Yurii / Ollie 🧑‍💻       | ✅ **Complete** | Vocabulary class implemented and tested.                                                                                                                                                                                          |
| 1.3  | **Model Choice & Training Data Gen** 🤔          | **CBOW chosen** ✅. `src/word2vec/dataset.py` implemented: generates `(context, target)` pairs ✅, creates PyTorch `Dataset` ✅.                                                                                       | James / Emil 🧑‍💻      | ✅ **Complete** | Data preparation pipeline for CBOW is ready.                                                                                                                                                                                      |
| 1.4  | **Word2Vec Model Implementation (PyTorch)** 🏗️    | `src/word2vec/model.py` defines `CBOW` class using `nn.Embedding` & `nn.Linear` ✅. Forward pass implements averaging logic ✅.                                                                                     | Yurii / James 🧑‍💻      | ✅ **Complete** | Core model architecture implemented.                                                                                                                                                                                                |
| 1.5  | **Loss Function & Negative Sampling** 📉          | **Currently using `nn.CrossEntropyLoss`** (Full Softmax) ✅. Negative Sampling **not yet implemented**.                                                                                                              | Ollie / Emil 🧑‍💻      | ⚠️ **Partial**  | Basic loss works, but optimized Negative Sampling is a potential future improvement if needed for speed/scalability (though current performance seems good).                                                                          |
| 1.6  | **Training Loop** 🔄                             | `src/word2vec/trainer.py` implements `train_epoch` & `train_model` ✅. Handles device (MPS) ✅, optimizer, loss, backprop, epochs ✅. **Integrated W&B logging** ✅. `train_word2vec.py` script orchestrates ✅.        | Team (Pair) 🧑‍🤝‍🧑    | ✅ **Complete** | Core training logic is functional and includes experiment tracking.                                                                                                                                                            |
| 1.7  | **Save Embeddings & Vocab** 💾                   | Vocab saved (`.json`) ✅. Model state (`.pth`, includes embeddings) saved ✅. **Implemented run-specific directories based on hyperparameters** ✅. Artifacts logged to W&B ✅.                                        | James / Yurii 🧑‍💻      | ✅ **Complete** | Artifacts are saved locally in an organized way and backed up/tracked on W&B.                                                                                                                                                     |
| 1.8  | **(Optional) Embedding Evaluation** ✅           | Evaluation notebook (`03_evaluate_word2vec.ipynb`) created ✅. Loads artifacts ✅. Implements nearest neighbors & analogy functions ✅. **Initial results show promising semantic learning** (esp. analogies like Paris-Berlin) ✅. | Emil / Ollie 🧑‍💻      | ✅ **Complete** | Basic intrinsic evaluation confirms embeddings learned meaningful relationships. Deeper evaluation (e.g., standard datasets) could be done but might not be necessary for this project's main goal.                                |
| 1.9  | **Configuration Management** ⚙️📄                | `config.yaml` created ✅. `train_word2vec.py` loads config and uses `argparse` for overrides ✅.                                                                                                                   | Team (All) 🤝          | ✅ **Complete** | Project configuration is centralized and flexible.                                                                                                                                                                                 |


**Phase 2: Regression Model Training** 📈


*   **Goal:** Train a model to predict `score_log1p` using custom embeddings & save it.
*   **Environment:** Local machine 💻.

| Step | Task                                   | Description & Details                                                                                                                                                                                                      | Potential Focus | Status |
| :--- | :------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------- | :----- |
| 2.1  | **Prepare HN Data & Load Embeddings** 📊 | Load cleaned HN dataset (`df_..._cleaned`). Load custom word embeddings & vocab saved in 1.7. 📂➡️🧠                                                                                                                    | Ollie / Emil 🧑‍💻  | ☐      |
| 2.2  | **Feature Engineering: Title Vectors** 🛠️ | Tokenize HN titles (using **same** vocab!). Average loaded embeddings for tokens (handle UNKs). Result: 1 vector per title. *Consider adding EDA features later.* ➕❓                                                  | James / Yurii 🧑‍💻  | ☐      |
| 2.3  | **Data Splitting** 🔪                   | Split data (features + `score_log1p` target) into Train/Test sets (80/20). Convert to Tensors. 🚆🧪                                                                                                                  | Emil / Ollie 🧑‍💻  | ☐      |
| 2.4  | **Regression Model Implementation** 🏗️  | Define simple PyTorch `nn.Module` for regression (e.g., `nn.Linear`). Input=vector dim, Output=1.                                                                                                                       | Yurii / James 🧑‍💻  | ☐      |
| 2.5  | **Regression Training Loop** 🔄         | Implement training loop: DataLoader BATCH , `nn.MSELoss` 📉, Optimizer ⚙️, train/eval steps. Predict `score_log1p`. Monitor loss 👀.                                                                                     | Ollie / Emil 🧑‍💻  | ☐      |
| 2.6  | **Evaluation** 💯                      | Evaluate on Test set. Metrics: MSE, MAE, RMSE (on log & original score scales via `np.expm1`). 📝                                                                                                                        | Team (All) 🤝   | ☐      |
| 2.7  | **Save Regression Model** 💾           | **Crucial:** Save trained regression model `state_dict` (`.pt`). Place in `models/`. Version it (e.g., "0.1.0"). 🏷️                                                                                                    | James / Yurii 🧑‍💻  | ☐      |

**Phase 3: API Implementation & Dockerization** 🐳🚀

*   **Goal:** Create FastAPI service, integrate models, package with Docker.
*   **Environment:** Local machine 💻 for dev/test, Docker runtime.

| Step | Task                                        | Description & Details                                                                                                                                                                                                                                                                        | Potential Focus | Status      |
| :--- | :------------------------------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------- | :---------- |
| 3.1  | **Project Structure Setup** 📁              | Create structure: `app/main.py`, `Dockerfile`, `requirements.txt`, `models/` (put saved models here).                                                                                                                                                                                         | Team (All) 🤝    | ☐           |
| 3.2  | **`requirements.txt`** 📄                   | List packages: `fastapi`, `uvicorn[standard]`, `torch`, `numpy`, `pandas`, etc. Dependency management!                                                                                                                                                                                   | Ollie / Emil 🧑‍💻 | ☐           |
| 3.3  | **FastAPI Basics (`main.py`)** ✨            | Basic app setup. Define `/ping` ✅, `/version` 🏷️. Set `model_version` variable.                                                                                                                                                                                                            | James / Yurii 🧑‍💻 | ☐           |
| 3.4  | **Logging Implementation (`main.py`)** ✍️    | Implement `log_request` (write JSON/str to `log_path`), `read_logs`. Use `/var/log/app`. Implement `/logs` endpoint. Persist logs! 💾                                                                                                                                                        | Emil / Ollie 🧑‍💻 | ☐           |
| 3.5  | **Prediction Logic (`main.py`)** 🔮         | Helper functions: <br> 1. Load embeddings & vocab 🧠. <br> 2. Load regression model `state_dict` ⚙️. <br> 3. Implement `predict_upvotes`: tokenize, avg embeddings, feed to model, return prediction (+ `np.expm1`?).                                                                         | James / Yurii 🧑‍💻 | ☐           |
| 3.6  | **`/how_many_upvotes` Endpoint (`main.py`)** 📮 | Implement POST endpoint: parse input, call `predict_upvotes`, calc latency ⏱️, format log msg 📝, call `log_request`, return prediction JSON.                                                                                                                                           | Ollie / Emil 🧑‍💻 | ☐           |
| 3.7  | **`Dockerfile`** 🐳                       | Create/Adapt Dockerfile: `python:3.11`, `WORKDIR`, `COPY` requirements/app/models, `RUN pip install`, `EXPOSE 8000`, `CMD`. 📦                                                                                                                                                               | James / Yurii 🧑‍💻 | ☐           |
| 3.8  | **Local Testing (uvicorn)** 🧪              | Run `uvicorn app.main:app --reload`. Test endpoints (`curl`, `/docs`). Check predictions work. 🐞🔫                                                                                                                                                                                        | Team (All) 🤝    | ☐           |
| 3.9  | **Docker Build & Run** 🏗️➡️🏃              | Build: `docker build -t user/repo:version .` <br> Run: `docker run --name dropout-disco -d -p 8000:8000 -v ./logs:/var/log/app user/repo:version`                                                                                                                                          | Team (All) 🤝    | ☐           |
| 3.10 | **Docker Testing & Logging** ✅🔍           | Test endpoints on container (`localhost:8000`). Verify predictions. Check host `./logs` dir for persistent logs. 👀                                                                                                                                                                            | Team (All) 🤝    | ☐           |